{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## inspired by https://commercedataservice.github.io/tutorial_biz_dynamics/\n",
    "from IPython.display import display\n",
    "import io, requests, zipfile\n",
    "import pandas as pd\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "\n",
    "from plotly import __version__\n",
    "## print (__version__) ## requires version >= 1.9.0\n",
    "\n",
    "## Generating Offline Graphs within Jupyter Notebook\n",
    "## https://plot.ly/python/offline/\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(msa_code, var_dict, para_dict):\n",
    "    ## catenate keys using str.join() method.\n",
    "    r = requests.get('http://api.census.gov/data/timeseries/bds/firms?get=' \\\n",
    "                     + ','.join(var_dict.keys()) \\\n",
    "                     + '&for=metropolitan+statistical+area:'\\\n",
    "                     + str(msa_code), \\\n",
    "                    params=para_dict)\n",
    "    \n",
    "    ## print(r)\n",
    "    ## when url returns empty content, return None\n",
    "    if r.content is b'': \n",
    "        return None\n",
    "    else:\n",
    "        ## read in data\n",
    "        data = pd.DataFrame(r.json())\n",
    "        \n",
    "        ## get columns names from first row and map them to the given names in var_dict\n",
    "        columns = data.iloc[0,:-len(para_dict)].map(var_dict)\n",
    "        \n",
    "        ## data we are interested in \n",
    "        data = data.iloc[1:,:-len(para_dict)]\n",
    "        \n",
    "        ## rename dataframe columns\n",
    "        data.columns = columns\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/udothemath1984/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## request data via https\n",
    "## https://www2.census.gov/econ/susb/data/\n",
    "r = requests.get('https://www2.census.gov/econ/susb/data/msa_codes_2007_to_2011.txt').content\n",
    "\n",
    "## read and parse data\n",
    "msa_code = pd.read_table(io.StringIO(r.decode('utf-8')), header=3, sep='   ') \n",
    "\n",
    "## rename columns\n",
    "msa_code.columns = ['code','name'] \n",
    "\n",
    "## get rid of micropolitan statistical areas\n",
    "msa_code = msa_code[msa_code['name'].str.contains('Metropolitan', case = False)]\n",
    "\n",
    "## clean up names\n",
    "msa_code['name'] = msa_code['name'].str.replace(' Metropolitan Statistical Area', '') \n",
    "\n",
    "## function to clean up MSA names, only keep the fist city and fist state\n",
    "def name_clean(s):\n",
    "    s_list = s.split(', ')\n",
    "    cities = s_list[0]\n",
    "    states = s_list[-1]\n",
    "    return ' '.join([cities.split('-')[0], states.split('-')[0]])\n",
    "\n",
    "## map the name_clean function to all MSA\n",
    "msa_code['name'] = msa_code['name'].map(name_clean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_key = '377a44f6cb37b1197c1b43db457bbb4e1330db9f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survival_rate(name, start_year):\n",
    "    \n",
    "    #fage4 is the firm age in a given year. Letters a through f represent years 0 through 5\n",
    "    fage4_values = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "    \n",
    "    #The data only covers up to 2013 (as of now), so we will limit the fage4_values to ones within 2013 minus start_year\n",
    "    if 2013 - start_year < 6:\n",
    "        fage4_values = fage4_values[0:(2013-start_year + 1)]\n",
    "\n",
    "    #var_dict contains the variables and their labels\n",
    "    var_dict = {'estabs': 'Establishments',\n",
    "                'emp': 'Employment',\n",
    "                'firms': 'Firms'}\n",
    "    \n",
    "    #set up empty array to accept results from get_data\n",
    "    result = []\n",
    "    \n",
    "    #grab the msa code based on the 'name' provided in the input parameters\n",
    "    code = msa_code[msa_code['name'].str.contains(name, case = False)]['code'].values[0]\n",
    "    ## print(code)  # 35620 for survival_rate('New York', 2009)\n",
    "    ## print(fage4_values)\n",
    "    #Loop from start year to the 5th year (or the cap year if end years exceed 2013)\n",
    "    for i in range(len(fage4_values)):\n",
    "        para_dict = {'fage4': fage4_values[i], 'time': start_year+i }\n",
    "        result.append(get_data(code, var_dict, para_dict))\n",
    "        ## print(para_dict)\n",
    "        \n",
    "    #The code was returning an error as not all variables were integer friendly (e.g. there was a phantom column of letters)\n",
    "    #Added in a drop statement to keep only variables 0:4 \n",
    "    df = pd.concat(result).iloc[:, 0:3].astype(int)\n",
    "    df.index = range(start_year,start_year+len(fage4_values))\n",
    "\n",
    "    ## print(df.index)\n",
    "    #Calculate point survival rate\n",
    "    #Step 1: Create denominator dataframe\n",
    "    #Shift rows up 1\n",
    "    df2 = df.shift(1)\n",
    "    \n",
    "    #Replace blank row with \n",
    "    df2.iloc[[0]] = df.iloc[[0]]\n",
    "    \n",
    "    #Step 2: Divide numerator (df) by denominator (df2)\n",
    "    df3 = df/df2\n",
    "\n",
    "    #Step 3: Calculate cumulative product on instantaneous survival rate table\n",
    "    df4 = df3.cumprod()*100\n",
    "\n",
    "    \n",
    "    ### start plotting using plotly\n",
    "    data = []\n",
    "    for label in df4.columns:\n",
    "        trace = go.Scatter(\n",
    "            x = df4.index,\n",
    "            y = df4[label].values,\n",
    "            name = label\n",
    "        )\n",
    "        data.append(trace)\n",
    "\n",
    "    layout = dict(title = 'Business Survival Rates, '+ name +' Metropolitan Area, Year: '+str(start_year),\n",
    "                  yaxis = dict(title = 'survival rate (%)'),\n",
    "                  xaxis = dict(title = 'year', nticks = len(df4)),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## draw down zip file, unzip, read in txt with specified encoding\n",
    "r = requests.get(\"http://www2.census.gov/geo/docs/maps-data/data/gazetteer/2015_Gazetteer/2015_Gaz_cbsa_national.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "geo = pd.read_table(z.open('2015_Gaz_cbsa_national.txt'), encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## clean the columns names and change to lower case\n",
    "## https://www.census.gov/geo/maps-data/data/gazetteer2015.html\n",
    "geo.columns = [field.rstrip().lower() for field in geo.columns]\n",
    "\n",
    "## get rid of micropolitan statistical areas and clean the names the same as msa_code \n",
    "geo = geo[geo['name'].str.contains('Metro', case = False)]\n",
    "geo['name'] = geo['name'].str.replace(' Metro Area', '')\n",
    "geo['name'] = geo['name'].map(name_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csafp</th>\n",
       "      <th>geoid</th>\n",
       "      <th>name</th>\n",
       "      <th>cbsa_type</th>\n",
       "      <th>aland</th>\n",
       "      <th>awater</th>\n",
       "      <th>aland_sqmi</th>\n",
       "      <th>awater_sqmi</th>\n",
       "      <th>intptlat</th>\n",
       "      <th>intptlong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.0</td>\n",
       "      <td>10420</td>\n",
       "      <td>Akron OH</td>\n",
       "      <td>1</td>\n",
       "      <td>2331619578</td>\n",
       "      <td>62018442</td>\n",
       "      <td>900.243</td>\n",
       "      <td>23.945</td>\n",
       "      <td>41.146639</td>\n",
       "      <td>-81.350110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>440.0</td>\n",
       "      <td>10540</td>\n",
       "      <td>Albany OR</td>\n",
       "      <td>1</td>\n",
       "      <td>5932815078</td>\n",
       "      <td>49654169</td>\n",
       "      <td>2290.673</td>\n",
       "      <td>19.172</td>\n",
       "      <td>44.488898</td>\n",
       "      <td>-122.537208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>10580</td>\n",
       "      <td>Albany NY</td>\n",
       "      <td>1</td>\n",
       "      <td>7282106737</td>\n",
       "      <td>172589034</td>\n",
       "      <td>2811.637</td>\n",
       "      <td>66.637</td>\n",
       "      <td>42.787920</td>\n",
       "      <td>-73.942348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106.0</td>\n",
       "      <td>10740</td>\n",
       "      <td>Albuquerque NM</td>\n",
       "      <td>1</td>\n",
       "      <td>24041256743</td>\n",
       "      <td>37921741</td>\n",
       "      <td>9282.382</td>\n",
       "      <td>14.642</td>\n",
       "      <td>35.116603</td>\n",
       "      <td>-106.456535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>408.0</td>\n",
       "      <td>10900</td>\n",
       "      <td>Allentown PA</td>\n",
       "      <td>1</td>\n",
       "      <td>3763879943</td>\n",
       "      <td>58581593</td>\n",
       "      <td>1453.242</td>\n",
       "      <td>22.618</td>\n",
       "      <td>40.789339</td>\n",
       "      <td>-75.398158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   csafp  geoid            name  cbsa_type        aland     awater  \\\n",
       "2  184.0  10420        Akron OH          1   2331619578   62018442   \n",
       "3  440.0  10540       Albany OR          1   5932815078   49654169   \n",
       "4  104.0  10580       Albany NY          1   7282106737  172589034   \n",
       "7  106.0  10740  Albuquerque NM          1  24041256743   37921741   \n",
       "9  408.0  10900    Allentown PA          1   3763879943   58581593   \n",
       "\n",
       "   aland_sqmi  awater_sqmi   intptlat   intptlong  \n",
       "2     900.243       23.945  41.146639  -81.350110  \n",
       "3    2290.673       19.172  44.488898 -122.537208  \n",
       "4    2811.637       66.637  42.787920  -73.942348  \n",
       "7    9282.382       14.642  35.116603 -106.456535  \n",
       "9    1453.242       22.618  40.789339  -75.398158  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(geo.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## http://mcdc.missouri.edu/data/popests/CBSA-EST2014-alldata.csv\n",
    "## read in data with specified encoding\n",
    "pop = pd.read_csv(\"http://mcdc.missouri.edu/data/popests/CBSA-EST2014-alldata.csv\", \n",
    "                  encoding = \"ISO-8859-1\")\n",
    "pop = pop[pop['LSAD']=='Metropolitan Statistical Area']\n",
    "pop = pop[['CBSA','POPESTIMATE2014']]\n",
    "pop.columns = ['geoid', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10180.0</td>\n",
       "      <td>168592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10420.0</td>\n",
       "      <td>703825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>154925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10540.0</td>\n",
       "      <td>119356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10580.0</td>\n",
       "      <td>880167.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoid  population\n",
       "3   10180.0    168592.0\n",
       "7   10420.0    703825.0\n",
       "10  10500.0    154925.0\n",
       "16  10540.0    119356.0\n",
       "18  10580.0    880167.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pop.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geo = geo.merge(pop, how='inner', left_on='geoid', right_on='geoid')\n",
    "\n",
    "#Merge msa_code to geo\n",
    "msa_code = msa_code.merge(geo[['name','intptlat','intptlong','population', 'aland_sqmi']],how='left', left_on='name', right_on='name')\n",
    "msa_code = msa_code.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>intptlat</th>\n",
       "      <th>intptlong</th>\n",
       "      <th>population</th>\n",
       "      <th>aland_sqmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10180</td>\n",
       "      <td>Abilene TX</td>\n",
       "      <td>32.452022</td>\n",
       "      <td>-99.718743</td>\n",
       "      <td>168592.0</td>\n",
       "      <td>2743.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10420</td>\n",
       "      <td>Akron OH</td>\n",
       "      <td>41.146639</td>\n",
       "      <td>-81.350110</td>\n",
       "      <td>703825.0</td>\n",
       "      <td>900.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10500</td>\n",
       "      <td>Albany GA</td>\n",
       "      <td>31.589303</td>\n",
       "      <td>-84.174913</td>\n",
       "      <td>154925.0</td>\n",
       "      <td>1932.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10580</td>\n",
       "      <td>Albany NY</td>\n",
       "      <td>42.787920</td>\n",
       "      <td>-73.942348</td>\n",
       "      <td>880167.0</td>\n",
       "      <td>2811.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10740</td>\n",
       "      <td>Albuquerque NM</td>\n",
       "      <td>35.116603</td>\n",
       "      <td>-106.456535</td>\n",
       "      <td>904587.0</td>\n",
       "      <td>9282.382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code            name   intptlat   intptlong  population  aland_sqmi\n",
       "0  10180      Abilene TX  32.452022  -99.718743    168592.0    2743.479\n",
       "1  10420        Akron OH  41.146639  -81.350110    703825.0     900.243\n",
       "2  10500       Albany GA  31.589303  -84.174913    154925.0    1932.597\n",
       "3  10580       Albany NY  42.787920  -73.942348    880167.0    2811.637\n",
       "4  10740  Albuquerque NM  35.116603 -106.456535    904587.0    9282.382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(msa_code.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for...\n",
      "    Akron OH\n",
      "    Albany NY\n",
      "    Albuquerque NM\n",
      "    Allentown PA\n",
      "    Amarillo TX\n",
      "    Anchorage AK\n",
      "    Ann Arbor MI\n",
      "    Asheville NC\n",
      "    Atlanta GA\n",
      "    Atlantic City NJ\n",
      "    Augusta GA\n",
      "    Austin TX\n",
      "    Bakersfield CA\n",
      "    Baltimore MD\n",
      "    Baton Rouge LA\n",
      "    Beaumont TX\n",
      "    Birmingham AL\n",
      "    Boise City ID\n",
      "    Boston MA\n",
      "    Boulder CO\n",
      "    Bremerton WA\n",
      "    Bridgeport CT\n",
      "    Brownsville TX\n",
      "    Buffalo NY\n",
      "    Canton OH\n",
      "    Cape Coral FL\n",
      "    Cedar Rapids IA\n",
      "    Charleston SC\n",
      "    Charlotte NC\n",
      "    Chattanooga TN\n",
      "    Chicago IL\n",
      "    Cincinnati OH\n",
      "    Clarksville TN\n",
      "    Cleveland OH\n",
      "    Colorado Springs CO\n",
      "    Columbia SC\n",
      "    Columbus GA\n",
      "    Columbus OH\n",
      "    Corpus Christi TX\n",
      "    Dallas TX\n",
      "    Davenport IA\n",
      "    Dayton OH\n",
      "    Deltona FL\n",
      "    Denver CO\n",
      "    Des Moines IA\n",
      "    Detroit MI\n",
      "    Duluth MN\n",
      "    Durham NC\n",
      "    El Paso TX\n",
      "    Erie PA\n",
      "    Eugene OR\n",
      "    Evansville IN\n",
      "    Fayetteville NC\n",
      "    Fayetteville AR\n",
      "    Flint MI\n",
      "    Fort Collins CO\n",
      "    Fort Smith AR\n",
      "    Fort Wayne IN\n",
      "    Fresno CA\n",
      "    Gainesville FL\n",
      "    Grand Rapids MI\n",
      "    Greeley CO\n",
      "    Green Bay WI\n",
      "    Greensboro NC\n",
      "    Greenville SC\n",
      "    Gulfport MS\n",
      "    Hagerstown MD\n",
      "    Harrisburg PA\n",
      "    Hartford CT\n",
      "    Hickory NC\n",
      "    Houston TX\n",
      "    Huntington WV\n",
      "    Huntsville AL\n",
      "    Indianapolis IN\n",
      "    Jackson MS\n",
      "    Jacksonville FL\n",
      "    Kalamazoo MI\n",
      "    Kansas City MO\n",
      "    Kennewick WA\n",
      "    Killeen TX\n",
      "    Kingsport TN\n",
      "    Knoxville TN\n",
      "    Lafayette LA\n",
      "    Lakeland FL\n",
      "    Lancaster PA\n",
      "    Lansing MI\n",
      "    Laredo TX\n",
      "    Las Vegas NV\n",
      "    Lexington KY\n",
      "    Lincoln NE\n",
      "    Little Rock AR\n",
      "    Los Angeles CA\n",
      "    Louisville/Jefferson County KY\n",
      "    Lubbock TX\n",
      "    Lynchburg VA\n",
      "    Madison WI\n",
      "    Manchester NH\n",
      "    McAllen TX\n",
      "    Memphis TN\n",
      "    Merced CA\n",
      "    Miami FL\n",
      "    Milwaukee WI\n",
      "    Minneapolis MN\n",
      "    Mobile AL\n",
      "    Modesto CA\n",
      "    Montgomery AL\n",
      "    Myrtle Beach SC\n",
      "    Naples FL\n",
      "    Nashville TN\n",
      "    New Haven CT\n",
      "    New Orleans LA\n",
      "    New York NY\n",
      "    Norwich CT\n",
      "    Ocala FL\n",
      "    Ogden UT\n",
      "    Oklahoma City OK\n",
      "    Olympia WA\n",
      "    Omaha NE\n",
      "    Orlando FL\n",
      "    Oxnard CA\n",
      "    Palm Bay FL\n",
      "    Pensacola FL\n",
      "    Peoria IL\n",
      "    Philadelphia PA\n",
      "    Phoenix AZ\n",
      "    Pittsburgh PA\n",
      "    Portland ME\n",
      "    Portland OR\n",
      "    Port St. Lucie FL\n",
      "    Providence RI\n",
      "    Provo UT\n",
      "    Raleigh NC\n",
      "    Reading PA\n",
      "    Reno NV\n",
      "    Richmond VA\n",
      "    Riverside CA\n",
      "    Roanoke VA\n",
      "    Rochester NY\n",
      "    Rockford IL\n",
      "    Sacramento CA\n",
      "    St. Louis MO\n",
      "    Salem OR\n",
      "    Salinas CA\n",
      "    Salisbury MD\n",
      "    Salt Lake City UT\n",
      "    San Antonio TX\n",
      "    San Diego CA\n",
      "    San Francisco CA\n",
      "    San Jose CA\n",
      "    San Luis Obispo CA\n",
      "    Santa Cruz CA\n",
      "    Santa Rosa CA\n",
      "    Savannah GA\n",
      "    Scranton PA\n",
      "    Seattle WA\n",
      "    Shreveport LA\n",
      "    South Bend IN\n",
      "    Spartanburg SC\n",
      "    Spokane WA\n",
      "    Springfield MA\n",
      "    Springfield MO\n",
      "    Stockton CA\n",
      "    Syracuse NY\n",
      "    Tallahassee FL\n",
      "    Tampa FL\n",
      "    Toledo OH\n",
      "    Trenton NJ\n",
      "    Tucson AZ\n",
      "    Tulsa OK\n",
      "    Utica NY\n",
      "    Vallejo CA\n",
      "    Virginia Beach VA\n",
      "    Visalia CA\n",
      "    Waco TX\n",
      "    Washington DC\n",
      "    Wichita KS\n",
      "    Wilmington NC\n",
      "    Winston NC\n",
      "    Worcester MA\n",
      "    York PA\n",
      "    Youngstown OH\n"
     ]
    }
   ],
   "source": [
    "## specify starting year of analysis\n",
    "start_year = 2008\n",
    "\n",
    "## letters indicating firm age\n",
    "fage4_values = ['a', 'b', 'c', 'd', 'e', 'f'] \n",
    "\n",
    "## deisred variables\n",
    "var_dict = {'firms': 'firms',\n",
    "            'emp': 'jobs'} \n",
    "\n",
    "## empty dataframe as placeholder\n",
    "df = pd.DataFrame(columns = ['name', 'population', 'aland_sqmi', 'lat', 'lon', '5-year firm survival', \n",
    "                             '5-year job survival', 'number of jobs', 'number of firms'])\n",
    "\n",
    "print('Fetching data for...')\n",
    "## iterate through every MSA with a population bigger than 250,000\n",
    "count = 0\n",
    "for idx, row in msa_code[msa_code['population']>=2.5e5].iterrows():\n",
    "    \n",
    "    ## code and name of current MSA\n",
    "    code = row['code']\n",
    "    print('    '+row['name'])\n",
    "    \n",
    "    ## place holder for results\n",
    "    result = []\n",
    "    \n",
    "    ## iterate through age 0 - 5\n",
    "    for i in range(6):\n",
    "        para_dict = {'fage4': fage4_values[i], 'time': start_year + i, 'key': api_key}\n",
    "        result.append(get_data(code, var_dict, para_dict))\n",
    "\n",
    "    ## check for empty results\n",
    "    if any([d is None for d in result]):\n",
    "        continue\n",
    "        \n",
    "    #The code was returning an error as not all variables were integer friendly (e.g. there was a phantom column of letters)\n",
    "    #Added in a drop statement to keep only variables 0:4 \n",
    "    df0 = pd.concat(result).iloc[:, 0:3].astype(int)\n",
    "    df0.index = range(start_year,start_year+len(fage4_values))\n",
    "\n",
    "    #Calculate point survival rate\n",
    "    #Step 1: Create denominator dataframe\n",
    "    #Shift rows up 1\n",
    "    df1 = df0.shift(1)\n",
    "    \n",
    "    #Replace blank row with \n",
    "    df1.iloc[[0]] = df0.iloc[[0]]\n",
    "    \n",
    "    #Step 2: Divide numerator (df) by denominator (df2)\n",
    "    df2 = df0/df1\n",
    "    \n",
    "\n",
    "    #Step 3: Calculate cumulative product on instantaneous survival rate table, keep only year 5\n",
    "    df3 = df2.cumprod()*100\n",
    "    \n",
    "    ## copy the initial number of jobs and firms\n",
    "    df.loc[code, ['number of jobs', 'number of firms']] = df0.iloc[[0]][['jobs', 'firms']].values\n",
    "\n",
    "     ## copy the initial survival probs\n",
    "    df.loc[code, ['5-year firm survival', '5-year job survival']] = df3.iloc[[5]][[ 'firms','jobs']].values\n",
    "\n",
    "    ## copy the namem population and location of MSA\n",
    "    df.loc[code, ['name', 'population', 'aland_sqmi', 'lat', 'lon']] = row[['name', 'population', 'aland_sqmi', 'intptlat','intptlong']].values \n",
    "    \n",
    "    ## Testing termination\n",
    "#     count += 1\n",
    "#     if count >= 3:\n",
    "#         break\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/28754658/whats-the-fastest-way-to-pickle-a-pandas-dataframe\n",
    "## build-in pickle method\n",
    "df.to_pickle('df_city_info.p')\n",
    "\n",
    "# import pickle\n",
    "# df.to_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_unit = 1000\n",
    "df['firm_population_ratio'] = per_unit* df['number of firms'] / df['population']    \n",
    "df['job_population_ratio'] = per_unit * df['number of jobs'] / df['population'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_bubblePlot(size_field, color_field): \n",
    "    scaling_for_job = 2000\n",
    "    \n",
    "    #bins = [0, 0.03, 0.1, 0.5, 0.9, 0.97, 1]\n",
    "    #bins = [0, 0.1, 0.5, 0.9, 1]\n",
    "    bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.9, 0.97, 1]\n",
    "    ## white     : rgb(255, 255, 255)\n",
    "    ## redish    : rgb(255, 0, 0)\n",
    "    ## yellowish : rgb(255, 255, 0)\n",
    "    ## bluish    : rgb(0, 0, 255)\n",
    "    ## cryan     : rgb(0, 255, 255)\n",
    "    ## yellow    \" rgb(255, 255, 0)\n",
    "    n_color_segment = len(bins) - 1\n",
    "    ## print(n_color_segment)\n",
    "    each_increment = float(256 / n_color_segment) \n",
    "    colors = [\"rgb(255, {}, {})\".format(255-i*each_increment, 255-i*each_increment) \\\n",
    "              for i in range(0,n_color_segment)]\n",
    "    \n",
    "    qs = df[color_field].quantile(bins).values\n",
    "    ## print(qs)\n",
    "    my_this = pd.qcut(df[color_field], bins, labels=[i for i in range(n_color_segment)])\n",
    "               \n",
    "    df['text'] = (df['name'] \n",
    "    + '<br>population: ' + (df['population']/1e6).map(lambda x: '%2.1f' % x) + ' million'\n",
    "    + '<br>' + size_field + ': ' + df[size_field].map(lambda x: '{:,}'.format(x))\n",
    "    + '<br>' + color_field + ': ' + df[color_field].map(lambda x: '%2.2f' % x) + '%')\n",
    "\n",
    "    trace0 = go.Scatter(\n",
    "        name='Area Size: Number of job',\n",
    "        x=list(df['population'].values),\n",
    "        y=list(df['aland_sqmi'].values),\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=[\"rgb(255, {}, {})\".format(255-i*each_increment, 255-i*each_increment) \\\n",
    "              for i in my_this],\n",
    "    #         opacity=[1, 0.8, 0.6, 0.4],\n",
    "            size=df[size_field].values/scaling_for_job\n",
    "        ),\n",
    "        text=df['text']\n",
    "    )\n",
    "    layout = dict(\n",
    "    #title = size_field+' created in 2008, grouped by '+color_field,\n",
    "        showlegend = True,\n",
    "        xaxis=dict(\n",
    "            title=\"Number of population\",\n",
    "            ),\n",
    "        yaxis=dict(\n",
    "            title=\"Size of city (mi^2)\",\n",
    "        ),\n",
    "        margin=go.Margin(\n",
    "        l=50,\n",
    "        r=50,\n",
    "        b=100,\n",
    "        t=100,\n",
    "        pad=4,\n",
    "        ),\n",
    "\n",
    "    )\n",
    "    \n",
    "    data = [trace0]    \n",
    "    fig = dict( data=data, layout=layout)\n",
    "    iplot(fig, filename='bubblechart-color')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_plot(size_field, color_field):\n",
    "    \n",
    "    ## value to scale down bubble size\n",
    "    scale = df[size_field].max()/4e3\n",
    "    \n",
    "    \n",
    "    ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.quantile.html\n",
    "    ## setting quantiles\n",
    "    bins = [0, 0.03, 0.1, 0.5, 0.9, 0.97, 1]\n",
    "    \n",
    "    ## setting colors\n",
    "    ##colors = ['#8c510a', '#d8b365', '#f6e8c3', '#c7eae5', '#5ab4ac', '#01665e']\n",
    "    n_color_segment = 6\n",
    "    each_increment = float(256 / n_color_segment) \n",
    "    ## white     : rgb(255, 255, 255)\n",
    "    ## redish    : rgb(255, 0, 0)\n",
    "    ## yellowish : rgb(255, 255, 0)\n",
    "    ## bluish    : rgb(0, 0, 255)\n",
    "    ## cryan     : rgb(0, 255, 255)\n",
    "    ## yellow    \" rgb(255, 255, 0)\n",
    "#     colors = [\"rgb(255,{},{})\".format(255-i*each_increment, 255-i*each_increment) \\\n",
    "#               for i in range(0,n_color_segment)]\n",
    "\n",
    "    colors = [\"rgb(255, {}, {})\".format(255-i*each_increment, 255-i*each_increment) \\\n",
    "              for i in range(0,n_color_segment)]\n",
    "    ##print(colors)\n",
    "    ## place holder for msa traces \n",
    "    msas = []\n",
    "    \n",
    "    ## text to show when mouse move over\n",
    "    df['text'] = (df['name'] \n",
    "        + '<br>population: ' + (df['population']/1e6).map(lambda x: '%2.1f' % x) + ' million'\n",
    "        + '<br>' + size_field + ': ' + df[size_field].map(lambda x: '{:,}'.format(x))\n",
    "        + '<br>' + color_field + ': ' + df[color_field].map(lambda x: '%2.2f' % x) + '%')\n",
    "    \n",
    "    ## calculate the corresponding values for each quantile\n",
    "    qs = df[color_field].quantile(bins).values\n",
    "    \n",
    "    ##print(qs)\n",
    "    \n",
    "    ## iterate through each group\n",
    "    for lower, upper, color in zip(qs[:-1], qs[1:], colors):\n",
    "        \n",
    "        ## handling lower bound\n",
    "        if color==colors[0]: \n",
    "            df_sub = df[(df[color_field]<upper)]\n",
    "            \n",
    "            ## format the value for display\n",
    "            name = '< {0:.0f}%'.format(upper)\n",
    "            \n",
    "        ## handling upper bound\n",
    "        elif color==colors[-1]: \n",
    "            df_sub = df[(df[color_field]>lower)]\n",
    "            name = '> {0:.0f}%'.format(lower)\n",
    "        ## other groups    \n",
    "        else: \n",
    "            df_sub = df[(df[color_field]>lower)&(df[color_field]<=upper)]\n",
    "            name = '{0:.0f}% - {1:.0f}%'.format(lower,upper)\n",
    "        \n",
    "        ## put data into a dictionary in plotly format\n",
    "        msa = dict(\n",
    "            type = 'scattergeo',\n",
    "            locationmode = 'USA-states',\n",
    "            lon = df_sub['lon'],\n",
    "            lat = df_sub['lat'],\n",
    "            text = df_sub['text'],\n",
    "            marker = dict(\n",
    "                size = df_sub[size_field]/scale,\n",
    "                color = color,\n",
    "                line = dict(width=0.5, color='rgb(40,40,40)'),\n",
    "                sizemode = 'area'\n",
    "            ),\n",
    "            name = name )\n",
    "        \n",
    "        ## append current data to placeholder\n",
    "        msas.append(msa)\n",
    "    \n",
    "    ## setting figure title and layout\n",
    "    layout = dict(\n",
    "        title = size_field + ' created in 2008, grouped by '+color_field,\n",
    "        showlegend = True,\n",
    "        margin=go.Margin(\n",
    "        l=50,\n",
    "        r=50,\n",
    "        b=100,\n",
    "        t=100,\n",
    "        pad=4\n",
    "        ),\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            landcolor = 'white',\n",
    "            subunitwidth=0.5,\n",
    "            countrywidth=0.5,\n",
    "            subunitcolor=\"gray\",\n",
    "            countrycolor=\"gray\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig = dict( data=msas, layout=layout )\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_plot('number of jobs', '5-year firm survival')\n",
    "map_bubblePlot('number of jobs', '5-year firm survival')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
